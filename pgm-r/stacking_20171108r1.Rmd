---
title : DS養成講座  銀行の顧客ターゲティング
author : Shinji KAWASOE
date   : 2017/11/08
output :
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: readable
---
# 概要

コンペの内容  
https://deepanalytics.jp/compe/1

使用するデータは、ある銀行の顧客属性データおよび、過去のキャンペーンでの接触情報、などで、これ
らのデータを元に、当該のキャンペーンの結果、口座を開設したかどうかを予測します。

## 投稿結果
0.92443

boostingやランダムフォレストを利用せずに、ロジスティック回帰や決定木で0.9オーバーは頑張っている
方だそうです。

## 手法の工夫
* Stackingで決定木とロジステック回帰を利用。
* pdaysで前回キャンペーン有無を分割し、それぞれでモデル作成
* month,dayよりDate型作成。最終接触date(lastdate)と前回キャンペーンdate(pdate)
* age, balance, durationの外れ値を除去し、オッズ比を線形化
* 全項目でモデル作成。

## その他
HoldOutでチューニングを試みたが、値が減少した。  
0.92443 → 0.91348  
変数の相関や目的変数への寄与方法などもう少し分析が必要。

## 注意点
最終接触時間(duration)はリーク(Leakage)にあたるパラメータなので、モデル作成としては不正解です。
接触時間は、未来の情報なのでモデル作成時にはない情報になります。  
リークの考え方は、本モデル作成後に講義で学んだことですので、以下を参照する上で注意が必要です。

# データ読込とデータ加工

```{r}
## 使用ライブラリ
library(dplyr)
library(rpart)
library(pROC)
library(ggplot2)
library(partykit)

## データ読込
train<-read.csv("../motodata/train.csv", header=TRUE)
test<-read.csv("../motodata/test.csv", header=TRUE)

## trainとtestを一度に加工できるようにまとめる。
test$y <- 9
combi <- rbind(train,test)
```
## モデル構築への工夫(検討)
ロジスティック回帰を利用する場合、非線形な変数や外れ値の影響を減らすことで精度が向上する。  
多重共線性がないか、相関が高い変数が説明変数に含まれないか確認する。  
参考：20171011_ロジスティック回帰.pdf

### 年齢(age)
年代ごとに対数オッズ$\frac{p}{1 - p}$の関係を確認し、線形性を持つように加工する。

```{r}
train %>%
  dplyr::mutate(age_c = floor(age/10)*10) %>%
  dplyr::group_by(age_c) %>%
  dplyr::summarise(p=mean(y)) %>%
  dplyr::ungroup(.) %>%
  dplyr::mutate(log_odds=log(p/(1-p))) %>%
  ggplot(mapping = aes(x=age_c, y=log_odds)) + geom_line()

```
50才でV字の形状なので、$x{\prime} = |50 - x|$として50で折り返して直線にする。

```{r}
train <- train %>%
  dplyr::mutate(age2=abs(50-age))

# 再び線形性の確認
train %>%
  dplyr::mutate(age_c = floor(age2/10)*10) %>%
  dplyr::group_by(age_c) %>%
  dplyr::summarise(p=mean(y)) %>%
  dplyr::ungroup(.) %>%
  dplyr::mutate(log_odds=log(p/(1-p))) %>%
  ggplot(mapping = aes(x=age_c, y=log_odds)) + geom_line()
```

### 年間平均残高(balance)
外れ値を確認する。

```{r}
hist(train$balance)
```

右に大きくゆがんでいるので、95%タイルで丸める。95%以上は95%値とする。
```{r}
## パーセンタイル点の確認
quantile(train$balance,probs=c(.05,.95))

## 丸め(ifelse(条件式, 真のとき返す値, 偽のとき返す値))
train <- train %>%
  dplyr::mutate(balance2=ifelse(balance >= quantile(balance,probs=.95),
                                quantile(balance,probs=.95),
                                balance))

## 外れ値の確認
hist(train$balance2)
```

### 最終接触時間(duration)
外れ値を確認し、丸める。
```{r}
## 外れ値の確認
hist(train$duration)

## パーセンタイル点の確認
quantile(train$duration ,probs=c(.05,.95))

## 丸め(ifelse(条件式, 真のとき返す値, 偽のとき返す値))上のみ
train <- train %>%
  dplyr::mutate(duration2=ifelse(duration >= quantile(duration,probs=.95),
                                quantile(duration,probs=.95),
                                duration))

## 外れ値の確認
hist(train$duration2)
```

対数オッズ$\frac{p}{1 - p}$の関係を確認し、線形性を持つように加工する。  

```{r}
train %>%
    dplyr::mutate(duration_c = floor(duration2/50)*50) %>%
    dplyr::group_by(duration_c) %>%
    dplyr::summarise(p=mean(y)) %>%  ####p反応率
    dplyr::ungroup(.) %>%
    dplyr::mutate(log_odds=log(p/(1-p))) %>%
    ggplot(mapping = aes(x=duration_c, y=log_odds)) + geom_line()
```

$y = \log x$のグラフに見えるので、$\sqrt{x}$をとる。

```{r}
train <- train %>%
    dplyr::mutate(duration3 = sqrt(duration2))

##再び線形性の確認
train %>%
    ## duration2ごとの対数オッズを計算
    dplyr::mutate(duration_c = floor(duration3/5)*5) %>%
    dplyr::group_by(duration_c) %>%
    dplyr::summarise(p=mean(y)) %>%  ####p反応率
    dplyr::ungroup(.) %>%
    dplyr::mutate(log_odds=log(p/(1-p))) %>%
    ggplot(mapping = aes(x=duration_c, y=log_odds)) + geom_line()
```

## 相関係数の確認
多重共線性を確認する。  
(めやす)相関係数をrとすると  

|\|r\||相関|
|---|---|
|0.7〜1|かなり強い相関がある|
|0.4〜0.7|やや相関あり|
|0.2〜0.4|弱い相関あり|
|0〜0.2|ほとんど相関なし|

```{r}
cor(train[,c("age2", "balance2", "duration3")])
```

結果、全て*ほとんど関係なし*なので、多重共線性の問題はないと考える。

## モデル構築に向けたデータ加工
検討結果より次の加工を実施する。

*最終接触時間(duration)は外れ値を0.995%tileを寄せる。線形にするため、ルートを取る。
*年齢(age)は、50で折り返し。
*年間平均残高(balance)は、95%tileを取る。

```{r}
combi <- combi %>%
    dplyr::mutate(duration2=ifelse(duration >= quantile(duration,probs=.995),
                                   quantile(duration,probs=.995),
                                   duration)) %>%
    dplyr::mutate(duration3 = sqrt(duration2)) %>%
    dplyr::mutate(age2=abs(50-age)) %>%
    dplyr::mutate(balance2=ifelse(balance >= quantile(balance,probs=.95),
                                  quantile(balance,probs=.95),
                                  balance))
```
## カテゴリデータへの加工(JOBのグループ化)
* 働いているか否か。
* majorかminorか。
```{r}
combi <- combi %>%
    dplyr::mutate(job2 = if_else(job %in% c('retired','students'), 'notworker', 'worker')) %>%
    dplyr::mutate(job2 = if_else(job == 'unknown' , 'unknown', job2)) %>%
    dplyr::mutate(job2 = as.factor(job2)) 

combi <- combi %>%
    dplyr::mutate(job3 = if_else(job %in% c('admin.','bule-collar','management','services','technician')
                               , 'major'
                               , 'minor')) %>%
    dplyr::mutate(job3 = as.factor(job3)) 
```
## モデル作成の準備
### trainとtestに分割する。
```{r}
train <- combi %>%
    dplyr::filter(y < 9)
test <- combi %>%
    dplyr::filter(y == 9) %>%
    dplyr::select(-y)
```

### 精度向上のため、前回キャンペーン有無でデータとモデルを分割する。

```{r}
train_old <- train %>%
    dplyr::filter(pdays > -1)
test_old <- test %>%
    dplyr::filter(pdays > -1)

train_new <- train %>%
    dplyr::filter(pdays==-1) %>%
    dplyr::select(-c(pdays,previous,poutcome))
test_new <- test %>%
    dplyr::filter(pdays==-1) %>%
    dplyr::select(-c(pdays,previous,poutcome))

## 前キャンペーンの日付求める
lct <- Sys.getlocale("LC_TIME"); Sys.setlocale("LC_TIME", "C")
train_old <- train_old %>%
    mutate(lastdate = as.POSIXct(as.Date(paste(day,month,"2017",sep=""),"%d%b%Y")))
test_old <- test_old %>%
    mutate(lastdate = as.POSIXct(as.Date(paste(day,month,"2017",sep=""),"%d%b%Y")))
train_old <- train_old %>%
    mutate(pdate = as.POSIXct(as.Date(paste(day,month,"2017",sep=""),"%d%b%Y") - pdays))
test_old <- test_old %>%
    mutate(pdate = as.POSIXct(as.Date(paste(day,month,"2017",sep=""),"%d%b%Y") - pdays))
Sys.setlocale("LC_TIME", lct)
```

# モデル構築(スタッキングの実装)
今回は決定木(rpart)とロジスティック回帰(glm)をロジスティック回帰(glm)でアンサンブル

## 前回キャンペーンがあるデータをターゲットとする。(Old)

```{r}
#再現性のため乱数シードを固定
set.seed(17)
#学習データをK個にグループ分け
K<-5
#sample(ベクトル, ランダムに取得する個数, 復元抽出の有無, ベクトルの各要素が抽出される確率)
train_old$cv_group<-sample(1:K, nrow(train_old), replace=TRUE, prob=rep(1/K, K))

#構築, 検証データ予測スコアの初期化
score_train_tree<-NULL
score_train_logi<-NULL
score_test_tree<-NULL
score_test_logi<-NULL
y<-NULL

#クロスバリデーション
for(j in 1:K){
  #構築, 検証データに分ける
  train_tmp<-train_old %>%
    dplyr::filter(cv_group!=j) %>%
    dplyr::select(-cv_group)
  test_tmp<-train_old %>%
    dplyr::filter(cv_group==j) %>%
    dplyr::select(-cv_group)

  ## 構築データでモデル構築(決定木)
  tree_tmp<-rpart(y~., data=train_tmp,
                  maxdepth=10, minbucket=12, cp=0.000008,
                  method="class", parms=list(split="gini"))
  
  ## 構築データでモデル構築(ロジスティック回帰)
  logi_tmp<-glm(y~., data=train_tmp, family=binomial(link="logit"))

  #モデル構築に使用していないデータの予測値と目的変数
  pred_train_tree<-predict(tree_tmp, test_tmp)[,2]
  pred_train_logi<-predict(logi_tmp, test_tmp, type="response")
  y<-c(y, test_tmp$y)
  
  score_train_tree<-c(score_train_tree, pred_train_tree)
  score_train_logi<-c(score_train_logi, pred_train_logi)
  
  
  #検証データの予測値
  pred_test_tree<-predict(tree_tmp, test_old)[,2]
  pred_test_logi<-predict(logi_tmp, test_old, type="response")
  
  score_test_tree<-cbind(score_test_tree, pred_test_tree)
  score_test_logi<-cbind(score_test_logi, pred_test_logi)
}

#余計な変数削除
train_old <- train_old %>%
  dplyr::select(-cv_group)

#検証データの予測値の平均
#apply(データ, 1, 関数)で行ごとに関数を適用する
score_test_tree<-apply(score_test_tree, 1, mean)
score_test_logi<-apply(score_test_logi, 1, mean)
m_dat_test1<-data.frame(tree=score_test_tree, logi=score_test_logi)

#メタモデル用変数作成
m_dat_train<-data.frame(tree=score_train_tree, logi=score_train_logi, y=y)

#メタモデル構築(今回はロジスティック回帰)
m_logi<-glm(y~., data=m_dat_train, family=binomial(link="logit"))

##検証データ適用1
#メタモデル適用
pred_test_m_logi1<-predict(m_logi, m_dat_test1, type="response")
submit1_old <- data.frame(id=test_old$id, score=pred_test_m_logi1)
```

### 前回キャンペーンがないデータをターゲットとする。(New)

```{r}
### New
#再現性のため乱数シードを固定
set.seed(17)
#学習データをK個にグループ分け
K<-5
#sample(ベクトル, ランダムに取得する個数, 復元抽出の有無, ベクトルの各要素が抽出される確率)
train_new$cv_group<-sample(1:K, nrow(train_new), replace=TRUE, prob=rep(1/K, K))

#構築, 検証データ予測スコアの初期化
score_train_tree<-NULL
score_train_logi<-NULL
score_test_tree<-NULL
score_test_logi<-NULL
y<-NULL

#クロスバリデーション
for(j in 1:K){
  #構築, 検証データに分ける
  train_tmp<-train_new %>%
    dplyr::filter(cv_group!=j) %>%
    dplyr::select(-cv_group)
  test_tmp<-train_new %>%
    dplyr::filter(cv_group==j) %>%
    dplyr::select(-cv_group)
  
  ## 構築データでモデル構築(決定木)
  tree_tmp<-rpart(y~., data=train_tmp,
                  maxdepth=10, minbucket=12, cp=0.000008,
                  method="class", parms=list(split="gini"))
  
  ## 構築データでモデル構築(ロジスティック回帰)
  logi_tmp<-glm(y~., data=train_tmp, family=binomial(link="logit"))
  
  #モデル構築に使用していないデータの予測値と目的変数
  pred_train_tree<-predict(tree_tmp, test_tmp)[,2]
  pred_train_logi<-predict(logi_tmp, test_tmp, type="response")
  y<-c(y, test_tmp$y)
  
  score_train_tree<-c(score_train_tree, pred_train_tree)
  score_train_logi<-c(score_train_logi, pred_train_logi)
  
  
  #検証データの予測値
  pred_test_tree<-predict(tree_tmp, test_new)[,2]
  pred_test_logi<-predict(logi_tmp, test_new, type="response")
  
  score_test_tree<-cbind(score_test_tree, pred_test_tree)
  score_test_logi<-cbind(score_test_logi, pred_test_logi)
  
}

#余計な変数削除
train_new <- train_new %>%
  dplyr::select(-cv_group)

#検証データの予測値の平均
#apply(データ, 1, 関数)で行ごとに関数を適用する
score_test_tree<-apply(score_test_tree, 1, mean)
score_test_logi<-apply(score_test_logi, 1, mean)
m_dat_test1<-data.frame(tree=score_test_tree, logi=score_test_logi)


#メタモデル用変数作成
m_dat_train<-data.frame(tree=score_train_tree, logi=score_train_logi, y=y)

#メタモデル構築(今回はロジスティック回帰)
m_logi<-glm(y~., data=m_dat_train, family=binomial(link="logit"))

##検証データ適用
#メタモデル適用
pred_test_m_logi1<-predict(m_logi, m_dat_test1, type="response")
submit1_new <- data.frame(id=test_new$id, score=pred_test_m_logi1)
```
## 予測
### 前回キャンペーンの有(Old)/無(New)をマージする。
```{r}
## Marge
submit1 <- rbind(submit1_old, submit1_new)

str(submit1)

write.table(submit1,
            file="../submit/submit_20171108_ens_tree_logi_1.csv",
            quote=F, sep=",", row.names=F, col.names=F)
```
